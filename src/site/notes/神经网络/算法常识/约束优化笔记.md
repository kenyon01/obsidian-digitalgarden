# 单目标约束优化问题：
## 数学形式：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728151704.png)
分为优化的目标和约束条件，其中约束条件分为等式约束和不等式约束。
没有约束条件之前，个体可以通过适应度值的不同比较谁好谁怀，但是有了约束条件之后，就不能简单的比较目标值了。
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728155951.png)
有了约束之后，我们还要评估一个解违反约束条件的程度。g是一个等式约束条件，h是一个不等式约束条件。由于等式约束条件满足非常困难，想要完全满足非常的困难，尤其是决策变量比较多的时候，这些约束是完全非线性的，点落在上面非常的困难，因此使用一个松弛的方式来对变量进行释放$\delta=10^{-3}~10^{-4}$ 。
如果G=0,那么就表示这个个体不违反约束条件，其组成可行域。
所以现在对一个x，需要从两方面考虑，一个是f，一个是g

## 三个简单的例子：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728160251.png)

在可行域中，等式约束条件就是一条线段，圈圈代表不同的等高线。
整个区域形成搜索域，其中红色的线构成可行域。

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728160704.png)
第二个是只修改了约束条件，其中的两个圈形成两个可行域，只满足一个就可以，在这里面寻找一个最优秀的解。这里面会形成一些bias，比如大的可行域比较好进，群体一下全部进入大圈，小的圈就会解比较稀疏，找不到最优解。多个可行域是约束优化的挑战之一。

第三个例子：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728161127.png)
最优解在边界上面，这样搜索方式会和前面有一些不一样。 这个位于边界的解搜索起来比较容易。
## 使用约束方法+进化算法来解决SCOP
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728164444.png)

将约束处理技术和进化算法整合起来构成了进化约束优化。
进化算法在进化的过程中，多样性是不断降低的，因为在不断选好的个体，会变得越来越贪婪。


  EA是用来寻找下一代解，约束处理技术是为了如何选择后代解，即既要考虑父代解，也要其约束违反程度。
  ![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728170548.png)
  只可能有两种情况，一种是在边界上，一种是在可行域里面。，两种 情况下处理起来可能有一些不同，具体的不同需要
  ![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728201337.png)
  最优解在边界的时候，这种情况比较复杂，有时候不可行解比可行解还要重要，此时不可行解可能包含了比可行解更加重要的信息。
  ![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728201538.png)
  此时在惩罚不可行解和寻找目标值之间就存在一个矛盾，怎么去平衡这约束违反和目标值

这是正常过程的演示：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728201912.png)


## 约束处理技术
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728202503.png)

达到均衡

## 惩罚函数法

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728202708.png)
惩罚函数法就是根据约束的违反程度G，再乘上一个因子r，然后对目标进行修正。
惩罚函数法的本质是通过构造惩罚项来将单目标优化问题转化为单目标的优化问题
缺陷是惩罚要因子是依赖于问题的，也就是很难确定一个合适的factor，factor的大小严重依赖于不同的问题。
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728203105.png)

现在最流行的方法是自适应的惩罚函数法







## 偏好法

使得可行解总是优于不可行解。
比如要么使用目标值，要么使用约束违反程度，两个指标不会同时使用。
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728203447.png)
分开用，有时候用x，有时候用G。但是不管怎么弄，总是要使得可行解优于不可行解
优点是将一个多目标优化（这里要考虑f和G两个指标）。
缺点是忽略了不可行解也包含的重要的信息。比如可行解在边界附近，从两侧搜索效率会更高一些，但是这种方法就会使得不可行域的解被抛弃掉。
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728203912.png)




## 多目标优化法

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728204046.png)
转化为多目标优化问题就是将每一个约束，当成一个多目标优化的目标，这样就将一个单目标或者多目标的约束优化问题转化为一个多目标优化问题，但是这样做也会有一些缺点，最普遍的就是“维数灾难”

就是当一个问题的约束增加的时候，比如几十个约束，这时多目标的维数也变成几十个。

   ![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728204542.png)

一些综述文件：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728204628.png)




## 一个方法：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728205348.png)

在上述的总结中，不管是惩罚函数法，还是偏好法，都是带着一种对不可行解的一种偏见，。也就是都在降低不可行解的适应度，使其失去多样性而慢慢消失，但是有些不可行解中的信息也同样重要。
转换多目标的方法虽然没有偏见，但是会使得维数灾难

王勇一种新方法，将单目标转换为一个双目标的优化，其中一个维度是目标值，一个维度是总的约束值。

这个和传统的多目标优化问题不同，当G为零的时候，会使得多目标优化问题退化到单目标优化问题

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728210339.png)

正是因为这种退化，与传统的多目标优化得到的一个pareto面不同，这里是一个端点
可行域中的点成为纵轴上黑色的一条线。线上都是可行域上的解。
转化为双目标优化与传统的双目标优化不同，不需要考虑整个PF，只需要考虑端点

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728211823.png)


没有说可行解一定比可行解好
也没有对不可行解进行惩罚


![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728212131.png)
这是是说当还没有收敛到PF时，由于阴影区域比较小，是的D的替换比较少，所以种群可能就停止进化或者局部最优了，所以又设计了一个存档和替换的准则：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728212525.png)
### ****改进：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728212622.png)
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728212713.png)


![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728212757.png)
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220728212847.png)


单目标约束优化已经相对成熟，一般是采用惩罚函数法、偏好法、和多目标优化法
其中偏好法又分为$\eplion$ 法、deb的可行解存在准则、随机排序法。
除此之外，也有一些上面方法整合起来。

##   多目标约束优化问题

多目标优化约束

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729150227.png)
一个多目标优化的经过约束后的PF分布成为下面几个部分：
1. MCOP和MOP拥有相同的PF
2. MCOP和MOP拥有一部分相同的PF，
3. MCOP的PF的一部分和MOP的PF相同另一部分由于约束产生了新的PF
4. MCOp和MOP的PF不同，由于约束禅产生了新的PF
这四种CPF都是可行域的边界

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729152602.png)deb在01年提出的约束优化问题是有问题的，因为那个问题的可行域占了整个搜索域的90%，那么这种情况下就算不使用约束优化算法，其他的优化算法也能起到比较好的效果，不比单独考虑约束问题。但是这个和现实中的约束优化为题明显不符合。因此当约束问题变得比较复杂之后，大家都开始尝试新的算法。

### 一些新的测试函数
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729153045.png)

### 约束处理技术
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729153151.png)
约束处理技术这几年并没有明显的更新，和单目标约束优化差不多的

## 一套测试函数
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729153254.png)
使用一组相似函数了进行构建，但是这样构造太简单了，所以再加一组周期调整函数。

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729153520.png)
可行域、PF都变成了离散的片段


![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729153620.png)
这个测试问题的几个特点：
1. 可行域可调，只需要调整外面的可行域的边界即可
2. 通过不断的添加周期函数来增加非线性的约束
3. 可以任意构造不同的PF的形态
4. 如果任意增加约束条件，使其变多
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729153931.png)

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729154001.png)

以上的测试问题都是针对目标空间的约束来形成的，但是在实际的情况中，在单目标优化中，对决策变量的约束可能会起到不同的效果，因此后面又对决策空间进行了约束的构建：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729154304.png)
一个大家都非常喜欢举的例子就是买汽车，舒适度和cost是冲突的，定时花费是有限的。

还有一些优化的目标，比如汽车的品牌，汽车SUV，。这些是无法体现出来的。

也比如买股票，怎么投资组合可以获得最大的收益。但是资金的总数目是有限的。投资组合是一个典型的约束多目标问题。
### 改进
因此构造了一个新的多目标优化问题
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729155059.png)
这个测试函数分为了三个部分：
首先构造了一个多目标的无约束优化问题，然后把目标空间中的约束加进来，然后把决策空间的约束加进来。

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729155601.png)
上面是一个例子，首先先构造一个多目标优化问题，其PF如图。然后对目标空间进行约束，然后再决策空间进行约束。然后就可以形成一个约束多目标优化问题。
这里需要指出的，当我们在构造目标空间的时候，我们可以看到约束对在目标空间中的施加的影响，但是看不到决策空间中的变化。在对决策空间中施加约束的时候，可以看到决策空间中的变化，但是看不到目标空间中的影响。因此，约束条件不可以乱加，在论文中作者对该怎么添加约束，提出了[[一些想法和讨论。

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729160222.png)
这些约束条件是直接从单目标优化的直接提取出来的用的，因为对单目标的约束已经研究的比较透彻。

**特点**

![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729160504.png)

## 解法
提出一个两阶段的框架：
![](https://raw.githubusercontent.com/kenyon01/image-host/main/img/20220729160605.png)

第一个阶段：由于约束是的可行域变得非常小，所以算法需要在第一个阶段快速的进入可行域，进入可行域之后，在其种群多样性还可以的时候，从多样性和收敛性两个部分进行引导
第二



